import os
import matplotlib.pylab as plt
import numpy as np
import scipy.io
import math
import sys
import tables
import pandas
import pickle as pkl
from scipy.stats import sem
from scipy.stats import pearsonr
from scipy.stats import spearmanr
from numpy.random import permutation
import miscellaneous
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
from sklearn.svm import LinearSVC
from scipy.stats import ortho_group 
from sklearn.linear_model import LogisticRegression
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import ShuffleSplit
from sklearn.model_selection import KFold,StratifiedKFold,StratifiedShuffleSplit
from sklearn.neural_network import MLPClassifier
from scipy import stats
from scipy.optimize import curve_fit

# In this script we evaluate generalization throughout learning.
# Behavior: proabability that choice = context after context switch
# Neural: decoding of context right after context switch. Classifier is trained on all the rest of trials (no context switch)

nan=float('nan')
minf=float('-inf')
pinf=float('inf')
def warn(*args, **kwargs):
    pass
import warnings
warnings.warn = warn

def adjust_spines(ax, spines):
    for loc, spine in ax.spines.items():
        if loc in spines: 
            if loc=='left':
                spine.set_position(('outward', 10))  # outward by 10 points
            if loc=='bottom':
                spine.set_position(('outward', 0))  # outward by 10 points
         #   spine.set_smart_bounds(True)
        else:
            spine.set_color('none')  # don't draw spine
    # turn off ticks where there is no spine
    if 'left' in spines:
        ax.yaxis.set_ticks_position('left')
    else:
        # no yaxis ticks
        ax.yaxis.set_ticks([])
    if 'bottom' in spines:
        ax.xaxis.set_ticks_position('bottom')
    else:
        # no xaxis ticks
        ax.xaxis.set_ticks([])


def order_files(x):
    ord_pre=[]
    for i in range(len(x)):
        ord_pre.append(x[i][1:9])
    ord_pre=np.array(ord_pre)
    order=np.argsort(ord_pre)
    return order

def gauss(x,mu,sig):
    return 1/(sig*np.sqrt(2*np.pi))*np.exp(-0.5*((x-mu)**2)/(sig**2))

def func(x,a,b):
    return 1.0/(1+np.exp(-a*x+b))

def func0(x,a,b):
    y=1.0/(1+np.exp(-a*x))
    return b*y

# Best for behavior
def func1(x,a,b,c):
    y=1.0/(1+np.exp(-a*x))
    return b*y+c

def func2(x,a,b,c):
    y=1.0/(1+np.exp(-a*x+c))
    return b*y

def func3(x,a,b,c,d):
    y=1.0/(1+np.exp(-a*x+d))
    return b*y+c

def func4(x,a,b):
    return a*x+b

def intercept(a,b):
    return b/a

def intercept0(a,b):
    return np.log(b/0.5-1)/(-a)

def intercept1(a,b,c):
    return np.log(b/(0.5-c)-1)/(-a)

def intercept2(a,b,c):
    return (np.log(b/0.5-1)-c)/(-a)

def intercept3(a,b,c,d):
    return (np.log(b/(0.5-c)-1)-d)/(-a)

def intercept4(a,b):
    return (0.5-b)/a

def calculate_ind_ch_corr(ind_ch,reward):
    n_forw=7
    n_ch=len(ind_ch)
    ind_ch_corr=np.zeros(n_ch)
    for i in range(n_ch):
        aa=(np.arange(n_forw)+ind_ch[i])
        bb_pre=aa*reward[aa]
        bb=bb_pre[bb_pre>0]
        ind_ch_corr[i]=bb[0]
    return np.array(ind_ch_corr,dtype=np.int16)

# This function returns the indices for trials where:
# - context change from 0 to 1 correct stimulus 0
# - context change from 0 to 1 correct stimulus 1
# - context change from 1 to 0 correct stimulus 0
# - context change from 1 to 0 correct stimulus 1 
def calculate_ind_ch_corr2(ind_ch01,ind_ch10,reward,stimulus):
    n_forw=7

    # Context change from 0 to 1
    ind_ch01_s0=[]
    ind_ch01_s1=[]
    n_ch01=len(ind_ch01)
    for i in range(n_ch01):
        aa=(np.arange(n_forw)+ind_ch01[i])
        bb_pre=aa*reward[aa]
        bb=bb_pre[bb_pre>0]
        if stimulus[bb[0]]==0:
            ind_ch01_s0.append(bb[0])
        if stimulus[bb[0]]==1:
            ind_ch01_s1.append(bb[0])

    # Context change from 1 to 0
    ind_ch10_s0=[]
    ind_ch10_s1=[]
    n_ch10=len(ind_ch10)
    for i in range(n_ch10):
        aa=(np.arange(n_forw)+ind_ch10[i])
        bb_pre=aa*reward[aa]
        bb=bb_pre[bb_pre>0]
        if stimulus[bb[0]]==0:
            ind_ch10_s0.append(bb[0])
        if stimulus[bb[0]]==1:
            ind_ch10_s1.append(bb[0])
    return np.array(ind_ch01_s0,dtype=np.int16),np.array(ind_ch01_s1,dtype=np.int16),np.array(ind_ch10_s0,dtype=np.int16),np.array(ind_ch10_s1,dtype=np.int16)

def func_eval_behav(index,t_back,t_forw,stimulus,choice,context):
    pp=nan*np.zeros((2,t_forw+t_back))
    for j in range(t_back):
        indj=(index-t_back+j)
        try:
            if stimulus[indj]==0:
                pp[0,j]=(choice[indj]==context[indj])
            if stimulus[indj]==1:
                pp[1,j]=(choice[indj]==context[indj])
        except:
            None
    for j in range(t_forw):
        indj=(index+j)
        try:
            if stimulus[indj]==0:
                pp[0,j+t_back]=(choice[indj]==context[indj])
            if stimulus[indj]==1:
                pp[1,j+t_back]=(choice[indj]==context[indj])            
        except:
            None
    return pp

def func_eval_neuro(index,t_back,t_forw,stimulus,context,fr,reg):
    #
    ind_del_pre=(index+(np.arange(t_back+t_forw)-t_back))
    ind_train_pre=np.arange(len(context))
    ind_del=ind_del_pre[ind_del_pre<=np.max(ind_train_pre)]
    ind_train=np.delete(ind_train_pre,ind_del)
    #
    cl=LogisticRegression(C=1/reg,class_weight='balanced')
    cl.fit(fr[ind_train],context[ind_train])
    choice=cl.predict(fr)
       
    pp=nan*np.zeros((2,t_forw+t_back))
    for j in range(t_back):
        indj=(index-t_back+j)
        try:
            if stimulus[indj]==0:
                pp[0,j]=(choice[indj]==context[indj])
            if stimulus[indj]==1:
                pp[1,j]=(choice[indj]==context[indj])
        except:
            None
    for j in range(t_forw):
        indj=(index+j)
        try:
            if stimulus[indj]==0:
                pp[0,j+t_back]=(choice[indj]==context[indj])
            if stimulus[indj]==1:
                pp[1,j+t_back]=(choice[indj]==context[indj])            
        except:
            None
    return pp

def fit_plot(xx,yy,t_back,t_forw,sig_kernel,maxfev,method,bounds,p0):
    kernel=gauss(xx,int((t_back+t_forw)/2.0)-t_back,sig_kernel)
    convo=np.convolve(yy,kernel,mode='same')

    # Cuidado con el +1!
    popt,pcov=curve_fit(func1,xx[(t_back+1):],yy[(t_back+1):],nan_policy='omit',maxfev=maxfev,bounds=bounds,p0=p0,method=method)
    #popt,pcov=curve_fit(func2,xx[t_back:],convo[t_back:],nan_policy='omit',maxfev=maxfev,bounds=bounds,p0=p0,method=method)
    fit_func=func1(xx[(t_back+1):],popt[0],popt[1],popt[2])#,popt[3])
    inter=intercept1(popt[0],popt[1],popt[2])#,popt[3])
    print ('Fit ',popt)
    print (pcov)
    print (inter,fit_func[1])
    # plt.scatter(xx,yy,color='blue',s=1)
    # #plt.scatter(xx,convo,color='green',s=1)
    # plt.plot(xx[(t_back+1):],fit_func,color='black')
    # plt.axvline(0,color='black',linestyle='--')
    # plt.plot(xx,0.5*np.ones(len(xx)),color='black',linestyle='--')
    # plt.ylim([-0.1,1.1])
    # plt.show()
    return fit_func,inter
  
#################################################

# Function 2 for both. Bounds and p0 are important. 
# Niels: t_back 20, t_forw 80, time window 200ms. No kernel. Groups of 1 session
# Galileo: t_back 20, t_forw 80, time window 300ms. No kernel. Groups of 3 sessions

monkey='Niels'
t_back=20
t_forw=80
sig_kernel=1 # not smaller than 1

talig='dots_on' #'response_edf' #dots_on
dic_time=np.array([0,300,300,300])# time pre, time post, bin size, step size (time pre always positive) 

thres=0
reg=1e0
maxfev=100000
method='dogbox'
bounds=([0,0,-0.5],[10,1,0.5])
p0=(0.05,0.5,0.5)

xx=np.arange(t_back+t_forw)-t_back

group_ref=np.array([-7 ,-6 ,-5 ,-4 ,-3 ,-2 ,-1 ,0  ,1  ,2  ,3  ,4  ,5  ,6  ,7  ])
if monkey=='Niels':
    #files_groups=[[0,4],[4,8],[8,12]]
    #files_groups=[[0,3],[3,6],[6,9],[9,12]]
    #files_groups=[[0,2],[2,4],[4,6],[6,8],[8,10],[10,12]]
    files_groups=[[0,1],[1,2],[2,3],[3,4],[4,5],[5,6],[6,7],[7,8],[8,9],[9,10],[10,11],[11,12]]

if monkey=='Galileo':
    #files_groups=[[0,10],[10,20],[20,30]]
    #files_groups=[[0,5],[5,10],[10,15],[15,20],[20,25],[25,30]]
    files_groups=[[0,3],[3,6],[6,9],[9,12],[12,15],[15,18],[18,21],[21,24],[24,27],[27,30]]
    #files_groups=[[0,2],[2,4],[4,6],[6,8],[8,10],[10,12],[12,14],[14,16],[16,18],[18,20],[20,22],[22,24],[24,26],[26,28],[28,30]]
    #files_groups=[[0,1],[1,2],[2,3],[3,4],[4,5],[5,6],[6,7],[7,8],[8,9],[9,10],[10,11],[11,12],[12,13],[13,14],[14,15],[15,16],[16,17],[17,18],[18,19],[19,20],[20,21],[21,22],[22,23],[23,24],[24,25],[25,26],[26,27],[27,28],[28,29],[29,30]]

abs_path='/home/ramon/Dropbox/Esteki_Kiani/data/unsorted/%s/'%(monkey) 
files_pre=np.array(os.listdir(abs_path))
order=order_files(files_pre)
files_all=np.array(files_pre[order])
print (files_all)

fit_beha=nan*np.zeros((2,2,len(files_groups),t_back+t_forw))
inter_beha=nan*np.zeros((2,2,len(files_groups)))
y0_beha=nan*np.zeros((2,2,len(files_groups)))
beha_te_unte=nan*np.zeros((2,2,len(files_groups),t_back+t_forw))

fit_neuro=nan*np.zeros((2,2,len(files_groups),t_back+t_forw))
inter_neuro=nan*np.zeros((2,2,len(files_groups)))
y0_neuro=nan*np.zeros((2,2,len(files_groups)))
neuro_te_unte=nan*np.zeros((2,2,len(files_groups),t_back+t_forw))
for hh in range(len(files_groups)):
    beha_tested_rlow=[]
    beha_tested_rhigh=[]
    beha_untested_rlow=[]
    beha_untested_rhigh=[]
    neuro_tested_rlow=[]
    neuro_tested_rhigh=[]
    neuro_untested_rlow=[]
    neuro_untested_rhigh=[]
    files=files_all[files_groups[hh][0]:files_groups[hh][1]]
    print (files)
    for kk in range(len(files)):
        print (files[kk])
        #Load data
        data=scipy.io.loadmat(abs_path+'%s'%(files[kk]),struct_as_record=False,simplify_cells=True)
        beha=miscellaneous.behavior(data)
        index_nonan=beha['index_nonan']
        # We discard first trial of session because we are interested in context changes
        stimulus=beha['stimulus'][1:]
        choice=beha['choice'][1:]
        coherence=beha['coherence_signed'][1:]
        coh_uq=np.unique(coherence)
        reward=beha['reward'][1:]
        rt=beha['reaction_time'][1:]
        context_pre=beha['context']
        ctx_ch=(context_pre[1:]-context_pre[0:-1])
        context=context_pre[1:] #FIX THIS. WE NEED A VARIABLE "SUBJECTIVE CONTEXT"
        ind_ch_pre=np.where(abs(ctx_ch)==1)[0] # ind_ch_pre index where there is a context change
        #ind_ch=np.where(abs(ctx_ch)==1)[0] # ind_ch_pre index where there is a context change
        indch_ct01_pre=np.where(ctx_ch==1)[0]
        indch_ct10_pre=np.where(ctx_ch==-1)[0]
        ind_ch=calculate_ind_ch_corr(ind_ch_pre,reward) # ind_ch first correct trial after context change (otherwise animal doesn't know there was a change)
        ind_ch01_s0,ind_ch01_s1,ind_ch10_s0,ind_ch10_s1=calculate_ind_ch_corr2(indch_ct01_pre,indch_ct10_pre,reward,stimulus)
        
        firing_rate_pre=miscellaneous.getRasters_unsorted(data,talig,dic_time,index_nonan,threshold=thres)
        firing_rate=miscellaneous.normalize_fr(firing_rate_pre)[1:,:,0]

        print (ind_ch01_s0,ind_ch01_s1,ind_ch10_s0,ind_ch10_s1)
        
        ##################################################
        # Behavior
        # Probability of Choice = Context for all possibilities: 01 0, 01 1, 10 0, 10 1

        # Numero 1 y 2 top
        for h in range(len(ind_ch01_s0)):
            cc_01_0=func_eval_behav(ind_ch01_s0[h],t_back,t_forw,stimulus,choice,context)
            beha_tested_rlow.append(cc_01_0[0]) #1
            beha_untested_rhigh.append(cc_01_0[1]) #2
            #print ('1 y 2 top',cc_01_0)
        # Numero 3 y 4 top
        for h in range(len(ind_ch01_s1)):
            cc_01_1=func_eval_behav(ind_ch01_s1[h],t_back,t_forw,stimulus,choice,context)
            beha_untested_rlow.append(cc_01_1[0]) #3
            beha_tested_rhigh.append(cc_01_1[1]) #4
            #print ('3 y 4 top',cc_01_1)
        # Numero 3 y 4 bottom           
        for h in range(len(ind_ch10_s0)):
            cc_10_0=func_eval_behav(ind_ch10_s0[h],t_back,t_forw,stimulus,choice,context)
            beha_untested_rlow.append(cc_10_0[1]) #3
            beha_tested_rhigh.append(cc_10_0[0]) #4
            #print ('4 y 3 bottom',cc_10_1)       
        # Numero 1 y 2 bottom           
        for h in range(len(ind_ch10_s1)):
            cc_10_1=func_eval_behav(ind_ch10_s1[h],t_back,t_forw,stimulus,choice,context)
            beha_tested_rlow.append(cc_10_1[1]) #1
            beha_untested_rhigh.append(cc_10_1[0]) #2
            #print ('2 y 1 bottom',cc_10_1)

        print (len(beha_tested_rlow),len(beha_untested_rhigh),len(beha_untested_rlow),len(beha_tested_rhigh))

        ##################################################
        # Neuro
        # Probability of Choice of classifier = Context for all possibilities: 01 0, 01 1, 10 0, 10 1

        # # Numero 1 y 2 top
        # for h in range(len(ind_ch01_s0)):
        #     cc_01_0=func_eval_neuro(ind_ch01_s0[h],t_back,t_forw,stimulus,context,firing_rate,reg)
        #     neuro_tested_rlow.append(cc_01_0[0]) #1
        #     neuro_untested_rhigh.append(cc_01_0[1]) #2
        #     #print ('1 y 2 top',cc_01_0)
        # # Numero 3 y 4 top
        # for h in range(len(ind_ch01_s1)):
        #     cc_01_1=func_eval_neuro(ind_ch01_s1[h],t_back,t_forw,stimulus,context,firing_rate,reg)
        #     neuro_untested_rlow.append(cc_01_1[0]) #3
        #     neuro_tested_rhigh.append(cc_01_1[1]) #4
        #     #print ('3 y 4 top',cc_01_1)
        # # Numero 3 y 4 bottom           
        # for h in range(len(ind_ch10_s0)):
        #     cc_10_0=func_eval_neuro(ind_ch10_s0[h],t_back,t_forw,stimulus,context,firing_rate,reg)
        #     neuro_untested_rlow.append(cc_10_0[1]) #3
        #     neuro_tested_rhigh.append(cc_10_0[0]) #4
        #     #print ('4 y 3 bottom',cc_10_1)       
        # # Numero 1 y 2 bottom           
        # for h in range(len(ind_ch10_s1)):
        #     cc_10_1=func_eval_neuro(ind_ch10_s1[h],t_back,t_forw,stimulus,context,firing_rate,reg)
        #     neuro_tested_rlow.append(cc_10_1[1]) #1
        #     neuro_untested_rhigh.append(cc_10_1[0]) #2
        #     #print ('2 y 1 bottom',cc_10_1)
        # ############################################

    # Behavior
    beha_te_unte[0,0,hh]=np.nanmean(beha_tested_rlow,axis=0)
    beha_te_unte[0,1,hh]=np.nanmean(beha_tested_rhigh,axis=0)
    beha_te_unte[1,0,hh]=np.nanmean(beha_untested_rlow,axis=0)
    beha_te_unte[1,1,hh]=np.nanmean(beha_untested_rhigh,axis=0)
    aa00=fit_plot(xx,beha_te_unte[0,0,hh],t_back,t_forw,sig_kernel,maxfev,method=method,p0=p0,bounds=bounds)
    aa01=fit_plot(xx,beha_te_unte[0,1,hh],t_back,t_forw,sig_kernel,maxfev,method=method,p0=p0,bounds=bounds)
    aa10=fit_plot(xx,beha_te_unte[1,0,hh],t_back,t_forw,sig_kernel,maxfev,method=method,p0=p0,bounds=bounds)
    aa11=fit_plot(xx,beha_te_unte[1,1,hh],t_back,t_forw,sig_kernel,maxfev,method=method,p0=p0,bounds=bounds)
    fit_beha[0,0,hh,(t_back+1):]=aa00[0]
    fit_beha[0,0,hh,0:t_back]=np.mean(beha_te_unte[0,0,hh,0:t_back])
    fit_beha[0,1,hh,(t_back+1):]=aa01[0]
    fit_beha[0,1,hh,0:t_back]=np.mean(beha_te_unte[0,1,hh,0:t_back])
    fit_beha[1,0,hh,(t_back+1):]=aa10[0]
    fit_beha[1,0,hh,0:t_back]=np.mean(beha_te_unte[1,0,hh,0:t_back])
    fit_beha[1,1,hh,(t_back+1):]=aa11[0]
    fit_beha[1,1,hh,0:t_back]=np.mean(beha_te_unte[1,1,hh,0:t_back])
    inter_beha[0,0,hh]=aa00[1]
    inter_beha[0,1,hh]=aa01[1]
    inter_beha[1,0,hh]=aa10[1]
    inter_beha[1,1,hh]=aa11[1]
    y0_beha[0,0,hh]=aa00[0][1]
    y0_beha[0,1,hh]=aa01[0][1]
    y0_beha[1,0,hh]=aa10[0][1]
    y0_beha[1,1,hh]=aa11[0][1]

    # Neuro
    neuro_te_unte[0,0,hh]=np.nanmean(neuro_tested_rlow,axis=0)
    neuro_te_unte[0,1,hh]=np.nanmean(neuro_tested_rhigh,axis=0)
    neuro_te_unte[1,0,hh]=np.nanmean(neuro_untested_rlow,axis=0)
    neuro_te_unte[1,1,hh]=np.nanmean(neuro_untested_rhigh,axis=0)
    aa00=fit_plot(xx,neuro_te_unte[0,0,hh],t_back,t_forw,sig_kernel,maxfev,method=method,p0=p0,bounds=bounds)
    aa01=fit_plot(xx,neuro_te_unte[0,1,hh],t_back,t_forw,sig_kernel,maxfev,method=method,p0=p0,bounds=bounds)
    aa10=fit_plot(xx,neuro_te_unte[1,0,hh],t_back,t_forw,sig_kernel,maxfev,method=method,p0=p0,bounds=bounds)
    aa11=fit_plot(xx,neuro_te_unte[1,1,hh],t_back,t_forw,sig_kernel,maxfev,method=method,p0=p0,bounds=bounds)
    fit_neuro[0,0,hh,(t_back+1):]=aa00[0]
    fit_neuro[0,0,hh,0:t_back]=np.mean(neuro_te_unte[0,0,hh,0:t_back])
    fit_neuro[0,1,hh,(t_back+1):]=aa01[0]
    fit_neuro[0,1,hh,0:t_back]=np.mean(neuro_te_unte[0,1,hh,0:t_back])
    fit_neuro[1,0,hh,(t_back+1):]=aa10[0]
    fit_neuro[1,0,hh,0:t_back]=np.mean(neuro_te_unte[1,0,hh,0:t_back])
    fit_neuro[1,1,hh,(t_back+1):]=aa11[0]
    fit_neuro[1,1,hh,0:t_back]=np.mean(neuro_te_unte[1,1,hh,0:t_back])
    inter_neuro[0,0,hh]=aa00[1]
    inter_neuro[0,1,hh]=aa01[1]
    inter_neuro[1,0,hh]=aa10[1]
    inter_neuro[1,1,hh]=aa11[1]
    y0_neuro[0,0,hh]=aa00[0][1]
    y0_neuro[0,1,hh]=aa01[0][1]
    y0_neuro[1,0,hh]=aa10[0][1]
    y0_neuro[1,1,hh]=aa11[0][1]

####################################################
# Behavior
beha_m=np.nanmean(beha_te_unte,axis=2)
beha_std=np.nanstd(beha_te_unte,axis=2)
beha_sem=sem(beha_te_unte,axis=2,nan_policy='omit')
beha_fit_m=np.nanmean(fit_beha,axis=2)
beha_fit_std=np.nanstd(fit_beha,axis=2)
beha_fit_sem=sem(fit_beha,axis=2,nan_policy='omit')

print ('Beha fit std Low R',beha_fit_std[:,0,21])
print ('Beha fit std High R',beha_fit_std[:,1,21])

ball_pre=np.nanmean(beha_te_unte,axis=1)
ball_m=np.nanmean(ball_pre,axis=1)
ball_sem=sem(ball_pre,axis=1,nan_policy='omit')
ball_fit_pre=np.nanmean(fit_beha,axis=1)
ball_fit_m=np.nanmean(ball_fit_pre,axis=1)
ball_fit_sem=sem(ball_fit_pre,axis=1,nan_policy='omit')

plt.scatter(xx,beha_m[0,0],color='green')
plt.scatter(xx,beha_m[1,0],color='blue')
plt.axvline(0,color='black',linestyle='--')
plt.plot(xx,0.5*np.ones(len(xx)),color='black',linestyle='--')
plt.plot(xx,beha_fit_m[0,0],color='green')
plt.fill_between(xx,beha_fit_m[0,0]-beha_fit_sem[0,0],beha_fit_m[0,0]+beha_fit_sem[0,0],color='green',alpha=0.5)
plt.plot(xx,beha_fit_m[1,0],color='blue')
plt.fill_between(xx,beha_fit_m[1,0]-beha_fit_sem[1,0],beha_fit_m[1,0]+beha_fit_sem[1,0],color='blue',alpha=0.5)
plt.ylim([0,1])
plt.xlabel('Trials after context change')
plt.ylabel('Prob. (Choice = Context)')
plt.show()

plt.scatter(xx,beha_m[0,1],color='green')
plt.scatter(xx,beha_m[1,1],color='blue')
plt.axvline(0,color='black',linestyle='--')
plt.plot(xx,0.5*np.ones(len(xx)),color='black',linestyle='--')
plt.plot(xx,beha_fit_m[0,1],color='green')
plt.fill_between(xx,beha_fit_m[0,1]-beha_fit_sem[0,1],beha_fit_m[0,1]+beha_fit_sem[0,1],color='green',alpha=0.5)
plt.plot(xx,beha_fit_m[1,1],color='blue')
plt.fill_between(xx,beha_fit_m[1,1]-beha_fit_sem[1,1],beha_fit_m[1,1]+beha_fit_sem[1,1],color='blue',alpha=0.5)
plt.ylim([0,1])
plt.xlabel('Trials after context change')
plt.ylabel('Prob. (Choice = Context)')
plt.show()

plt.scatter(xx,ball_m[0],color='green')
plt.scatter(xx,ball_m[1],color='blue')
plt.axvline(0,color='black',linestyle='--')
plt.plot(xx,0.5*np.ones(len(xx)),color='black',linestyle='--')
plt.plot(xx,ball_fit_m[0],color='green')
plt.fill_between(xx,ball_fit_m[0]-ball_fit_sem[0],ball_fit_m[0]+ball_fit_sem[0],color='green',alpha=0.5)
plt.plot(xx,ball_fit_m[1],color='blue')
plt.fill_between(xx,ball_fit_m[1]-ball_fit_sem[1],ball_fit_m[1]+ball_fit_sem[1],color='blue',alpha=0.5)
plt.ylim([0,1])
plt.xlabel('Trials after context change')
plt.ylabel('Prob. (Choice = Context)')
plt.show()

width=0.2
ind_plot=21
plt.bar(-width/2.0,beha_m[0,0,ind_plot],yerr=beha_sem[0,0,ind_plot],color='green',width=width)
plt.bar(+width/2.0,beha_m[1,0,ind_plot],yerr=beha_sem[1,0,ind_plot],color='blue',width=width)
plt.bar(1-width/2.0,beha_m[0,1,ind_plot],yerr=beha_sem[0,1,ind_plot],color='green',width=width)
plt.bar(1+width/2.0,beha_m[1,1,ind_plot],yerr=beha_sem[1,1,ind_plot],color='blue',width=width)
plt.ylim([0,1])
plt.ylabel('Prob. (Choice = Context)')
plt.show()

######################################################
# Neuro

neu_m=np.nanmean(neuro_te_unte,axis=2)
neu_sem=sem(neuro_te_unte,axis=2,nan_policy='omit')
neu_fit_m=np.nanmean(fit_neuro,axis=2)
neu_fit_sem=sem(fit_neuro,axis=2,nan_policy='omit')

nall_pre=np.nanmean(neuro_te_unte,axis=1)
nall_m=np.nanmean(nall_pre,axis=1)
nall_sem=sem(nall_pre,axis=1,nan_policy='omit')

nall_fit_pre=np.nanmean(fit_neuro,axis=1)
nall_fit_m=np.nanmean(nall_fit_pre,axis=1)
nall_fit_sem=sem(nall_fit_pre,axis=1,nan_policy='omit')

plt.scatter(xx,neu_m[0,0],color='green')
plt.scatter(xx,neu_m[1,0],color='blue')
plt.axvline(0,color='black',linestyle='--')
plt.plot(xx,0.5*np.ones(len(xx)),color='black',linestyle='--')
plt.plot(xx,neu_fit_m[0,0],color='green')
plt.fill_between(xx,neu_fit_m[0,0]-neu_fit_sem[0,0],neu_fit_m[0,0]+neu_fit_sem[0,0],color='green',alpha=0.5)
plt.plot(xx,neu_fit_m[1,0],color='blue')
plt.fill_between(xx,neu_fit_m[1,0]-neu_fit_sem[1,0],neu_fit_m[1,0]+neu_fit_sem[1,0],color='blue',alpha=0.5)
plt.ylim([0,1])
plt.xlabel('Trials after context change')
plt.ylabel('Prob. (Choice = Context)')
plt.show()

plt.scatter(xx,neu_m[0,1],color='green')
plt.scatter(xx,neu_m[1,1],color='blue')
plt.axvline(0,color='black',linestyle='--')
plt.plot(xx,0.5*np.ones(len(xx)),color='black',linestyle='--')
plt.plot(xx,neu_fit_m[0,1],color='green')
plt.fill_between(xx,neu_fit_m[0,1]-neu_fit_sem[0,1],neu_fit_m[0,1]+neu_fit_sem[0,1],color='green',alpha=0.5)
plt.plot(xx,neu_fit_m[1,1],color='blue')
plt.fill_between(xx,neu_fit_m[1,1]-neu_fit_sem[1,1],neu_fit_m[1,1]+neu_fit_sem[1,1],color='blue',alpha=0.5)
plt.ylim([0,1])
plt.xlabel('Trials after context change')
plt.ylabel('Prob. (Choice = Context)')
plt.show()

plt.scatter(xx,nall_m[0],color='green')
plt.scatter(xx,nall_m[1],color='blue')
plt.axvline(0,color='black',linestyle='--')
plt.plot(xx,0.5*np.ones(len(xx)),color='black',linestyle='--')
plt.plot(xx,nall_fit_m[0],color='green')
plt.fill_between(xx,nall_fit_m[0]-nall_fit_sem[0],nall_fit_m[0]+nall_fit_sem[0],color='green',alpha=0.5)
plt.plot(xx,nall_fit_m[1],color='blue')
plt.fill_between(xx,nall_fit_m[1]-nall_fit_sem[1],nall_fit_m[1]+nall_fit_sem[1],color='blue',alpha=0.5)
plt.ylim([0,1])
plt.xlabel('Trials after context change')
plt.ylabel('Prob. (Choice = Context)')
plt.show()

width=0.2
ind_plot=21
plt.bar(-width/2.0,neu_m[0,0,ind_plot],yerr=neu_sem[0,0,ind_plot],color='green',width=width)
plt.bar(+width/2.0,neu_m[1,0,ind_plot],yerr=neu_sem[1,0,ind_plot],color='blue',width=width)
plt.bar(1-width/2.0,neu_m[0,1,ind_plot],yerr=neu_sem[0,1,ind_plot],color='green',width=width)
plt.bar(1+width/2.0,neu_m[1,1,ind_plot],yerr=neu_sem[1,1,ind_plot],color='blue',width=width)
plt.ylim([0,1])
plt.ylabel('Prob. (Choice = Context)')
plt.show()
